#!/usr/bin/env python3
"""
Test Gemini API Connection (New google.genai package)
"""

import os
from dotenv import load_dotenv
from google import genai
from google.genai import types

# Load environment variables
load_dotenv()

GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
LLM_MODEL = os.getenv('LLM_MODEL', 'gemini-2.0-flash-exp')

def test_gemini_connection():
    """Test Gemini API connection with a simple conversation"""

    print("\n" + "="*60)
    print("  ğŸ¤– GEMINI API CONNECTION TEST (New API)")
    print("="*60)

    # Check API key
    if not GOOGLE_API_KEY:
        print("\nâŒ Error: GOOGLE_API_KEY not found in .env file")
        return False

    print(f"\nğŸ”‘ API Key: {GOOGLE_API_KEY[:20]}...")
    print(f"ğŸ“¦ Model: {LLM_MODEL}")

    try:
        # Create client
        client = genai.Client(api_key=GOOGLE_API_KEY)
        print("\nâœ… Client created successfully")

        # List available models
        print("\nğŸ“‹ Available Models:")
        try:
            models = client.models.list()
            count = 0
            for model in models:
                print(f"   - {model.name}")
                count += 1
                if count >= 5:  # Show only first 5 models
                    print("   ... (more models available)")
                    break
        except Exception as e:
            print(f"   âš ï¸  Could not list models: {e}")

        # Test simple conversation
        print("\n" + "="*60)
        print("  ğŸ’¬ TEST CONVERSATION")
        print("="*60)

        print(f"\nğŸ§ª Testing model: {LLM_MODEL}")
        print("ğŸ“ Prompt: 'Hello! Please respond in Korean. What is 1+1?'")

        # Generate response
        print("\nâ³ Generating response...")
        response = client.models.generate_content(
            model=LLM_MODEL,
            contents="Hello! Please respond in Korean. What is 1+1?"
        )

        print("\nâœ… Response received!")
        print("\n" + "-"*60)
        print("ğŸ¤– Gemini Response:")
        print("-"*60)
        print(response.text)
        print("-"*60)

        # Test with system instruction (for KSUR context)
        print("\n" + "="*60)
        print("  ğŸ’¬ TEST WITH SYSTEM INSTRUCTION")
        print("="*60)

        print("\nğŸ§ª Testing with KSUR medical context...")
        print("ğŸ“ Prompt: 'What is PSUR in pharmacovigilance?'")

        print("\nâ³ Generating response...")
        response2 = client.models.generate_content(
            model=LLM_MODEL,
            contents="What is PSUR in pharmacovigilance? Please answer briefly in Korean.",
            config=types.GenerateContentConfig(
                system_instruction="You are a pharmaceutical regulatory expert specializing in PSUR (Periodic Safety Update Report) analysis."
            )
        )

        print("\nâœ… Response received!")
        print("\n" + "-"*60)
        print("ğŸ¤– Gemini Response (with system instruction):")
        print("-"*60)
        print(response2.text)
        print("-"*60)

        # Token count test
        print("\n" + "="*60)
        print("  ğŸ“Š TOKEN COUNT TEST")
        print("="*60)

        test_text = "This is a test message for token counting in KSUR system."
        print(f"\nğŸ“ Text: '{test_text}'")

        try:
            token_response = client.models.count_tokens(
                model=LLM_MODEL,
                contents=test_text
            )
            print(f"\nâœ… Token count: {token_response.total_tokens}")
        except Exception as e:
            print(f"\nâš ï¸  Token counting error: {e}")

        # Test structured output (JSON mode)
        print("\n" + "="*60)
        print("  ğŸ“‹ JSON MODE TEST")
        print("="*60)

        print("\nğŸ§ª Testing JSON output for data extraction...")
        print("ğŸ“ Prompt: 'Extract product info: ì½”ë¯¸ë‚˜í‹°ì£¼, í™”ì´ì'")

        print("\nâ³ Generating response...")
        response3 = client.models.generate_content(
            model=LLM_MODEL,
            contents="Extract the following information in JSON format: Product name: ì½”ë¯¸ë‚˜í‹°ì£¼, Company: í•œêµ­í™”ì´ìì œì•½. Return only JSON with keys: product_name, company_name",
            config=types.GenerateContentConfig(
                response_mime_type="application/json"
            )
        )

        print("\nâœ… Response received!")
        print("\n" + "-"*60)
        print("ğŸ¤– Gemini Response (JSON):")
        print("-"*60)
        print(response3.text)
        print("-"*60)

        print("\n" + "="*60)
        print("  âœ… ALL TESTS PASSED!")
        print("="*60)
        print("\nâœ… New google.genai API is working correctly")
        print("âœ… Ready for KSUR system integration")
        print("âœ… JSON mode available for structured data extraction")
        print("\n")

        return True

    except Exception as e:
        print(f"\nâŒ Error during test: {e}")
        import traceback
        traceback.print_exc()
        print("\n" + "="*60)
        print("  âŒ TEST FAILED!")
        print("="*60)
        print("\n")
        return False

if __name__ == '__main__':
    success = test_gemini_connection()
    exit(0 if success else 1)
