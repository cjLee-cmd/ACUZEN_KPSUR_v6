/**
 * LLM Client (Google Gemini API)
 * LLM ì—°ê²° ë° í”„ë¡¬í”„íŠ¸ ì‹¤í–‰
 */

import { CONFIG, Storage, DateHelper } from './config.js';

class LLMClient {
    constructor() {
        this.apiKey = null;
        this.currentModel = CONFIG.LLM.DEFAULT_MODEL;
        this.dialogHistory = [];
    }

    /**
     * API í‚¤ ì„¤ì •
     */
    setApiKey(apiKey) {
        this.apiKey = apiKey;
        Storage.set(CONFIG.STORAGE_KEYS.GOOGLE_API_KEY, apiKey);
        console.log('âœ… Gemini API key set');
    }

    /**
     * API í‚¤ ê°€ì ¸ì˜¤ê¸°
     */
    getApiKey() {
        if (!this.apiKey) {
            this.apiKey = Storage.get(CONFIG.STORAGE_KEYS.GOOGLE_API_KEY);
        }
        return this.apiKey;
    }

    /**
     * ëª¨ë¸ ë³€ê²½
     */
    setModel(model) {
        if (Object.values(CONFIG.LLM.MODELS).includes(model)) {
            this.currentModel = model;
            console.log('âœ… Model changed to:', model);
            return true;
        }
        console.error('âŒ Invalid model:', model);
        return false;
    }

    /**
     * Gemini API í˜¸ì¶œ
     */
    async generateContent(prompt, options = {}) {
        const apiKey = this.getApiKey();

        if (!apiKey) {
            throw new Error('Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
        }

        const model = options.model || this.currentModel;
        const url = `${CONFIG.LLM.API_ENDPOINT}/${model}:generateContent?key=${apiKey}`;

        const requestBody = {
            contents: [{
                parts: [{
                    text: prompt
                }]
            }],
            generationConfig: {
                temperature: options.temperature || 0.7,
                topK: options.topK || 40,
                topP: options.topP || 0.95,
                maxOutputTokens: options.maxOutputTokens || 8192,
            }
        };

        try {
            const startTime = Date.now();

            const response = await fetch(url, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(requestBody)
            });

            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(`HTTP ${response.status}: ${errorData.error?.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`);
            }

            const data = await response.json();
            const duration = ((Date.now() - startTime) / 1000).toFixed(2);

            // ì‘ë‹µ ì¶”ì¶œ
            const text = data.candidates?.[0]?.content?.parts?.[0]?.text;

            if (!text) {
                throw new Error('ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
            }

            // ëŒ€í™” ë¡œê·¸ ì €ì¥
            this.logDialog(prompt, text, model, duration);

            console.log(`âœ… LLM response received (${duration}s)`);

            return {
                success: true,
                text: text,
                model: model,
                duration: duration
            };

        } catch (error) {
            console.error('âŒ LLM request failed:', error.message);
            return {
                success: false,
                error: error.message
            };
        }
    }

    /**
     * íŒŒì¼ ë¶„ë¥˜ (RAW ID íƒœê¹…)
     */
    async classifyDocument(filename, content) {
        const prompt = `ë‹¹ì‹ ì€ ì œì•½ ë¬¸ì„œ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ë¬¸ì„œ ìœ í˜•ì— í•´ë‹¹í•˜ëŠ”ì§€ RAW IDë¥¼ ì„ íƒí•˜ì„¸ìš”.

**íŒŒì¼ëª…**: ${filename}

**ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°**:
${content.substring(0, 2000)}

**RAW ID ëª©ë¡**:
${Object.entries(CONFIG.RAW_IDS).map(([id, name]) => `- ${id}: ${name}`).join('\n')}

**ì§€ì¹¨**:
1. íŒŒì¼ëª…ê³¼ ë‚´ìš©ì„ ë©´ë°€íˆ ë¶„ì„í•˜ì„¸ìš”.
2. ê°€ì¥ ì í•©í•œ RAW IDë¥¼ ì„ íƒí•˜ì„¸ìš”.
3. ì‘ë‹µ í˜•ì‹: RAW IDë§Œ ì¶œë ¥ (ì˜ˆ: RAW2.1)
4. í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ "UNKNOWN"ì„ ì¶œë ¥í•˜ì„¸ìš”.

**RAW ID**:`;

        const result = await this.generateContent(prompt, {
            temperature: 0.3,
            maxOutputTokens: 50
        });

        if (result.success) {
            const rawId = result.text.trim().toUpperCase();

            // ìœ íš¨ì„± ê²€ì¦
            if (rawId === 'UNKNOWN') {
                return { success: true, rawId: null, needsUserInput: true };
            }

            if (CONFIG.RAW_IDS[rawId]) {
                return { success: true, rawId: rawId };
            }

            // ìœ íš¨í•˜ì§€ ì•Šì€ RAW ID
            return { success: false, error: `ìœ íš¨í•˜ì§€ ì•Šì€ RAW ID: ${rawId}` };
        }

        return result;
    }

    /**
     * ë§ˆí¬ë‹¤ìš´ ë³€í™˜
     */
    async convertToMarkdown(content, filename, rawId) {
        const prompt = `ë‹¹ì‹ ì€ ë¬¸ì„œ ë³€í™˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ ë¬¸ì„œë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.

**íŒŒì¼ëª…**: ${filename}
**ë¬¸ì„œ ìœ í˜•**: ${rawId} - ${CONFIG.RAW_IDS[rawId]}

**ì›ë³¸ ë‚´ìš©**:
${content}

**âš ï¸ ì¤‘ìš” ê·œì¹™**:
1. **ì ˆëŒ€ë¡œ ë‚´ìš©ì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€í˜•í•˜ì§€ ë§ˆì„¸ìš”**
2. **ì›ë³¸ ë¬¸ì„œ ê·¸ëŒ€ë¡œ ë³€í™˜**í•˜ì„¸ìš”
3. í…Œì´ë¸”, ë‚ ì§œ, ìˆ«ì, í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ë³´ì¡´í•˜ì„¸ìš”
4. ìš”ì•½í•˜ê±°ë‚˜ ì¬êµ¬ì„±í•˜ì§€ ë§ˆì„¸ìš”
5. ë§ˆí¬ë‹¤ìš´ í¬ë§·ë§Œ ì ìš©í•˜ì„¸ìš”

**ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ê²°ê³¼**:`;

        return await this.generateContent(prompt, {
            temperature: 0.1,
            maxOutputTokens: 8192
        });
    }

    /**
     * ë°ì´í„° ì¶”ì¶œ (CS/PH/Table)
     */
    async extractData(markdownContent, dataDefinitions, rawId) {
        const prompt = `ë‹¹ì‹ ì€ ì œì•½ ë°ì´í„° ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œì—ì„œ ìš”ì²­ëœ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**ë¬¸ì„œ ìœ í˜•**: ${rawId} - ${CONFIG.RAW_IDS[rawId]}

**ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ**:
${markdownContent}

**ì¶”ì¶œí•  ë°ì´í„° ëª©ë¡**:
${dataDefinitions}

**ğŸš« ì ˆëŒ€ ê·œì¹™**:
1. **ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”** â†’ "DATA_NOT_FOUND" ë°˜í™˜
2. **ì¶©ëŒí•˜ëŠ” ë°ì´í„°ëŠ” ì„ì˜ë¡œ ì„ íƒí•˜ì§€ ë§ˆì„¸ìš”** â†’ ëª¨ë“  ë²„ì „ì„ ë‚˜ì—´
3. **ì¶”ì¸¡í•˜ê±°ë‚˜ ì¶”ì •í•˜ì§€ ë§ˆì„¸ìš”** â†’ ë¬¸ì„œì— ìˆëŠ” ê·¸ëŒ€ë¡œë§Œ ì¶”ì¶œ

**ì‘ë‹µ í˜•ì‹**:
\`\`\`json
{
  "CS0_ì„±ë¶„ëª…": "ì¶”ì¶œëœ ê°’" ë˜ëŠ” "DATA_NOT_FOUND",
  "CS1_ë¸Œëœë“œëª…": "ì¶”ì¶œëœ ê°’" ë˜ëŠ” "DATA_NOT_FOUND"
}
\`\`\`

**ì¶”ì¶œ ê²°ê³¼**:`;

        return await this.generateContent(prompt, {
            temperature: 0.1,
            maxOutputTokens: 4096
        });
    }

    /**
     * ëŒ€í™” ë¡œê·¸ ì €ì¥
     */
    logDialog(userMsg, responseMsg, model, duration) {
        const dialog = {
            timestamp: DateHelper.formatISO(),
            model: model,
            duration: duration,
            user: userMsg,
            response: responseMsg
        };

        this.dialogHistory.push(dialog);
    }

    /**
     * ëŒ€í™” ë¡œê·¸ ë‚´ë³´ë‚´ê¸° (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)
     */
    exportDialogHistory(reportName) {
        const timestamp = DateHelper.formatYYMMDD_hhmmss();
        const filename = `${reportName}_${timestamp}.md`;

        let markdown = `# LLM Dialog History: ${reportName}\n\n`;
        markdown += `**ìƒì„± ì‹œê°„**: ${DateHelper.formatISO()}\n\n`;
        markdown += `---\n\n`;

        this.dialogHistory.forEach((dialog, index) => {
            markdown += `## Dialog ${index + 1}\n\n`;
            markdown += `**ì‹œê°„**: ${dialog.timestamp}\n`;
            markdown += `**ëª¨ë¸**: ${dialog.model}\n`;
            markdown += `**ì†Œìš” ì‹œê°„**: ${dialog.duration}s\n\n`;
            markdown += `### [User Msg.]\n\n`;
            markdown += `\`\`\`\n${dialog.user}\n\`\`\`\n\n`;
            markdown += `### [Resp. Msg]\n\n`;
            markdown += `\`\`\`\n${dialog.response}\n\`\`\`\n\n`;
            markdown += `---\n\n`;
        });

        return { filename, content: markdown };
    }

    /**
     * ëŒ€í™” ë¡œê·¸ ì´ˆê¸°í™”
     */
    clearDialogHistory() {
        this.dialogHistory = [];
        console.log('âœ… Dialog history cleared');
    }
}

// Singleton instance
const llmClient = new LLMClient();

export default llmClient;
