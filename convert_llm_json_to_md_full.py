#!/usr/bin/env python3
import json
import sys
from datetime import datetime

def convert_json_to_markdown(json_file, output_file):
    """JSON íŒŒì¼ì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜ (ì „ì²´ ë‚´ìš© í¬í•¨)"""
    
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    md_lines = []
    
    # í—¤ë”
    md_lines.append("# LLM ëŒ€í™” ë¡œê·¸ (ì „ì²´)\n\n")
    md_lines.append(f"**ìº¡ì²˜ ì‹œê°„**: {data['capturedAt']}\n")
    md_lines.append(f"**íŒŒì¼ ê°œìˆ˜**: {data['fileCount']}\n")
    md_lines.append(f"**ëŒ€í™” ê°œìˆ˜**: {len(data['conversationLog'])}\n\n")
    md_lines.append("---\n\n")
    
    # ê° ëŒ€í™” ì²˜ë¦¬
    for idx, conv in enumerate(data['conversationLog'], 1):
        md_lines.append(f"## ëŒ€í™” #{idx}\n\n")
        md_lines.append(f"**íƒ€ì„ìŠ¤íƒ¬í”„**: {conv['timestamp']}\n")
        md_lines.append(f"**íƒ€ì…**: {conv['type']}\n\n")
        
        # ìš”ì²­ ì„¹ì…˜
        md_lines.append("### ğŸ“¤ ìš”ì²­ (Request)\n\n")
        md_lines.append(f"- **ë©”ì„œë“œ**: {conv['request']['method']}\n")
        
        url = conv['request']['url'].split('?')[0]
        md_lines.append(f"- **URL**: `{url}`\n\n")
        
        # ìš”ì²­ ë³¸ë¬¸ êµ¬ì¡°
        body = conv['request']['body']
        md_lines.append("#### ìš”ì²­ ë³¸ë¬¸ êµ¬ì¡°\n\n")
        md_lines.append("```json\n")
        structure = {
            'contents_count': len(body.get('contents', [])),
            'systemInstruction_length': len(body.get('systemInstruction', {}).get('parts', [{}])[0].get('text', '')),
            'generationConfig': body.get('generationConfig', {})
        }
        md_lines.append(json.dumps(structure, indent=2, ensure_ascii=False))
        md_lines.append("\n```\n\n")
        
        # ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­ (ì „ì²´)
        system_instruction = body.get('systemInstruction', {}).get('parts', [{}])[0].get('text', '')
        if system_instruction:
            md_lines.append("#### ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­ (System Instruction)\n\n")
            md_lines.append(f"**ê¸¸ì´**: {len(system_instruction):,} ë¬¸ì\n\n")
            md_lines.append("```\n")
            md_lines.append(system_instruction)  # ì „ì²´ ì¶œë ¥
            md_lines.append("\n```\n\n")
        
        # ì‚¬ìš©ì ì…ë ¥ (ì „ì²´)
        user_content = body.get('contents', [{}])[0].get('parts', [{}])[0].get('text', '')
        md_lines.append("#### ì‚¬ìš©ì ì…ë ¥ (User Contents)\n\n")
        md_lines.append(f"**ê¸¸ì´**: {len(user_content):,} ë¬¸ì\n\n")
        md_lines.append("```\n")
        md_lines.append(user_content)  # ì „ì²´ ì¶œë ¥
        md_lines.append("\n```\n\n")
        
        # ì‘ë‹µ ì„¹ì…˜
        md_lines.append("### ğŸ“¥ ì‘ë‹µ (Response)\n\n")
        md_lines.append(f"- **ìƒíƒœ ì½”ë“œ**: {conv['response']['status']}\n")
        
        response_data = conv['response'].get('data', {})
        md_lines.append(f"- **ëª¨ë¸**: {response_data.get('modelVersion', 'N/A')}\n\n")
        
        # ì‘ë‹µ í…ìŠ¤íŠ¸ (ì „ì²´)
        candidates = response_data.get('candidates', [{}])
        if candidates:
            response_text = candidates[0].get('content', {}).get('parts', [{}])[0].get('text', '')
            md_lines.append("#### ì‘ë‹µ í…ìŠ¤íŠ¸\n\n")
            md_lines.append(f"**ê¸¸ì´**: {len(response_text):,} ë¬¸ì\n\n")
            md_lines.append("```markdown\n")
            md_lines.append(response_text)  # ì „ì²´ ì¶œë ¥
            md_lines.append("\n```\n\n")
            
            # ë©”íƒ€ë°ì´í„°
            md_lines.append("#### ë©”íƒ€ë°ì´í„°\n\n")
            md_lines.append(f"- **Finish Reason**: `{candidates[0].get('finishReason', 'N/A')}`\n")
            md_lines.append(f"- **Safety Ratings**: {len(candidates[0].get('safetyRatings', []))} í•­ëª©\n\n")
            
            # Safety Ratings ìƒì„¸
            safety_ratings = candidates[0].get('safetyRatings', [])
            if safety_ratings:
                md_lines.append("**Safety Ratings ìƒì„¸**:\n\n")
                for rating in safety_ratings:
                    md_lines.append(f"- {rating.get('category', 'N/A')}: {rating.get('probability', 'N/A')}\n")
                md_lines.append("\n")
            
            # Token Count
            usage = response_data.get('usageMetadata', {})
            if usage:
                md_lines.append("**Token Count**:\n\n")
                md_lines.append(f"- Prompt Tokens: {usage.get('promptTokenCount', 0):,}\n")
                md_lines.append(f"- Candidates Tokens: {usage.get('candidatesTokenCount', 0):,}\n")
                md_lines.append(f"- Total Tokens: {usage.get('totalTokenCount', 0):,}\n\n")
        
        md_lines.append("---\n\n")
    
    # íŒŒì¼ ì €ì¥
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(''.join(md_lines))
    
    print(f"âœ… ë³€í™˜ ì™„ë£Œ: {output_file}")
    print(f"   - ëŒ€í™” ê°œìˆ˜: {len(data['conversationLog'])}")
    print(f"   - ì¶œë ¥ í¬ê¸°: {len(''.join(md_lines)):,} ë¬¸ì")

if __name__ == '__main__':
    json_file = 'LLM_Conversation_20260101_013724.json'
    output_file = 'LLM_Conversation_20260101_013724_FULL.md'
    
    convert_json_to_markdown(json_file, output_file)
