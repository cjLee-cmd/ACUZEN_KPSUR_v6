#!/usr/bin/env python3
"""
Gemini API PSUR Generation Test
Model: gemini-3-flash-preview
"""

import os
import json
import requests
from datetime import datetime

# API Configuration
API_KEY = "AIzaSyDPuqdY4s2tQ9qwyGSiLs6V0Xo2k_7xPF4"
BASE_URL = "https://generativelanguage.googleapis.com/v1beta/models"

# File paths
BASE_DIR = "/Users/cjlee/Documents/진행중/ACUZEN/02_KSUR_v6/90_Test"
CONTEXT_FILE = f"{BASE_DIR}/01_Context/PSUR_Generation_Context.md"
USER_INPUT_FILE = f"{BASE_DIR}/01_Context/RawData_Definition.md"
OUTPUT_DIR = f"{BASE_DIR}/05_Output"

def read_file(filepath):
    with open(filepath, 'r', encoding='utf-8') as f:
        return f.read()

def call_gemini_api(prompt, model, max_tokens=8192):
    url = f"{BASE_URL}/{model}:generateContent?key={API_KEY}"
    
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {
            "temperature": 0.3,
            "topK": 40,
            "topP": 0.95,
            "maxOutputTokens": max_tokens,
        }
    }
    
    print(f"\n{'='*60}")
    print(f"Model: {model}")
    print(f"Max Output Tokens: {max_tokens}")
    print(f"{'='*60}")
    
    response = requests.post(url, headers={"Content-Type": "application/json"}, json=payload, timeout=180)
    
    if response.status_code != 200:
        error_data = response.json()
        error_msg = error_data.get('error', {}).get('message', 'Unknown error')
        print(f"Error {response.status_code}: {error_msg}")
        
        # Token limit retry
        if 'token' in error_msg.lower() or 'limit' in error_msg.lower():
            if max_tokens < 32768:
                return call_gemini_api(prompt, model, 32768)
            elif max_tokens < 65536:
                return call_gemini_api(prompt, model, 65536)
        return None
    
    return response.json()

def main():
    print("=" * 60)
    print("PSUR Generation Test with Gemini API")
    print(f"Model: gemini-2.0-flash (gemini-3-flash-preview fallback)")
    print(f"Started at: {datetime.now()}")
    print("=" * 60)
    
    # Read files
    print("\n[1] Reading files...")
    context = read_file(CONTEXT_FILE)
    user_input = read_file(USER_INPUT_FILE)
    
    # Truncate if too long
    if len(user_input) > 80000:
        user_input = user_input[:80000] + "\n\n[... 이하 생략 ...]"
    
    print(f"    Context: {len(context):,} chars")
    print(f"    User Input: {len(user_input):,} chars")
    
    # Build prompt
    prompt = f"""## System Context
{context}

---

## User Input: RawData Definition
{user_input}

---

## Task
위 컨텍스트와 데이터 정의를 바탕으로, PSUR 보고서의 **00_표지** 섹션을 작성해주세요.

### 테스트 제품 정보:
- 성분명 (CS0): 메만틴염산염
- 브랜드명 (CS1): 글리빅사정
- 회사명 (CS2): 대웅바이오(주)
- 보고종료날짜 (CS4): 2025-04-30
- 국내허가일 (CS5): 2018-11-10
- 버전넘버 (CS7): 1.0

### 출력 형식:
마크다운 형식으로 완성된 표지를 출력하세요.
"""

    print(f"\n[2] Total prompt: {len(prompt):,} chars")
    
    # Try models
    models = ["gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro"]
    
    for model in models:
        print(f"\n[3] Trying: {model}")
        result = call_gemini_api(prompt, model)
        
        if result and 'candidates' in result:
            text = result['candidates'][0]['content']['parts'][0]['text']
            print(f"\n{'='*60}")
            print(f"SUCCESS - Model: {model}")
            print(f"Response length: {len(text):,} chars")
            print("="*60)
            print("\n### GENERATED OUTPUT ###\n")
            print(text)
            
            # Save
            os.makedirs(f"{OUTPUT_DIR}/sections", exist_ok=True)
            with open(f"{OUTPUT_DIR}/sections/00_표지_generated.md", 'w') as f:
                f.write(f"# Generated by {model}\n# {datetime.now()}\n\n{text}")
            print(f"\nSaved to: {OUTPUT_DIR}/sections/00_표지_generated.md")
            return
    
    print("\nAll models failed!")

if __name__ == "__main__":
    main()
