#!/usr/bin/env python3
import json
import sys
from datetime import datetime

def truncate_text(text, max_length=2000):
    """í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ê¸¸ì´ë¡œ ìë¥´ê³  ìƒëµ í‘œì‹œ ì¶”ê°€"""
    if len(text) <= max_length:
        return text
    return text[:max_length] + f"\n\n... (ìƒëµ, ì´ {len(text):,} ë¬¸ì)"

def convert_json_to_markdown(json_file, output_file):
    """JSON íŒŒì¼ì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
    
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    md_lines = []
    
    # í—¤ë”
    md_lines.append("# LLM ëŒ€í™” ë¡œê·¸\n")
    md_lines.append(f"**ìº¡ì²˜ ì‹œê°„**: {data['capturedAt']}\n")
    md_lines.append(f"**íŒŒì¼ ê°œìˆ˜**: {data['fileCount']}\n")
    md_lines.append(f"**ëŒ€í™” ê°œìˆ˜**: {len(data['conversationLog'])}\n")
    md_lines.append("\n---\n")
    
    # ê° ëŒ€í™” ì²˜ë¦¬
    for idx, conv in enumerate(data['conversationLog'], 1):
        md_lines.append(f"\n## ëŒ€í™” #{idx}\n")
        md_lines.append(f"\n**íƒ€ì„ìŠ¤íƒ¬í”„**: {conv['timestamp']}\n")
        md_lines.append(f"**íƒ€ì…**: {conv['type']}\n")
        
        # ìš”ì²­ ì„¹ì…˜
        md_lines.append("\n### ğŸ“¤ ìš”ì²­ (Request)\n")
        md_lines.append(f"\n- **ë©”ì„œë“œ**: {conv['request']['method']}\n")
        
        url = conv['request']['url'].split('?')[0]
        md_lines.append(f"- **URL**: `{url}`\n")
        
        # ìš”ì²­ ë³¸ë¬¸ êµ¬ì¡°
        body = conv['request']['body']
        md_lines.append("\n#### ìš”ì²­ ë³¸ë¬¸ êµ¬ì¡°\n")
        md_lines.append("```json\n")
        structure = {
            'contents_count': len(body.get('contents', [])),
            'systemInstruction_length': len(body.get('systemInstruction', {}).get('parts', [{}])[0].get('text', '')),
            'generationConfig': body.get('generationConfig', {})
        }
        md_lines.append(json.dumps(structure, indent=2, ensure_ascii=False))
        md_lines.append("\n```\n")
        
        # ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­
        system_instruction = body.get('systemInstruction', {}).get('parts', [{}])[0].get('text', '')
        if system_instruction:
            md_lines.append("\n#### ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­ (System Instruction)\n")
            md_lines.append(f"\n**ê¸¸ì´**: {len(system_instruction):,} ë¬¸ì\n")
            md_lines.append("\n```\n")
            md_lines.append(truncate_text(system_instruction, 3000))
            md_lines.append("\n```\n")
        
        # ì‚¬ìš©ì ì…ë ¥
        user_content = body.get('contents', [{}])[0].get('parts', [{}])[0].get('text', '')
        md_lines.append("\n#### ì‚¬ìš©ì ì…ë ¥ (User Contents)\n")
        md_lines.append(f"\n**ê¸¸ì´**: {len(user_content):,} ë¬¸ì\n")
        md_lines.append("\n```\n")
        md_lines.append(truncate_text(user_content, 3000))
        md_lines.append("\n```\n")
        
        # ì‘ë‹µ ì„¹ì…˜
        md_lines.append("\n### ğŸ“¥ ì‘ë‹µ (Response)\n")
        md_lines.append(f"\n- **ìƒíƒœ ì½”ë“œ**: {conv['response']['status']}\n")
        
        response_data = conv['response'].get('data', {})
        md_lines.append(f"- **ëª¨ë¸**: {response_data.get('modelVersion', 'N/A')}\n")
        
        # ì‘ë‹µ í…ìŠ¤íŠ¸
        candidates = response_data.get('candidates', [{}])
        if candidates:
            response_text = candidates[0].get('content', {}).get('parts', [{}])[0].get('text', '')
            md_lines.append("\n#### ì‘ë‹µ í…ìŠ¤íŠ¸\n")
            md_lines.append(f"\n**ê¸¸ì´**: {len(response_text):,} ë¬¸ì\n")
            md_lines.append("\n```markdown\n")
            md_lines.append(response_text)
            md_lines.append("\n```\n")
            
            # ë©”íƒ€ë°ì´í„°
            md_lines.append("\n#### ë©”íƒ€ë°ì´í„°\n")
            md_lines.append(f"\n- **Finish Reason**: `{candidates[0].get('finishReason', 'N/A')}`\n")
            md_lines.append(f"- **Safety Ratings**: {len(candidates[0].get('safetyRatings', []))} í•­ëª©\n")
            
            usage = response_data.get('usageMetadata', {})
            if usage:
                md_lines.append(f"- **Token Count**:\n")
                md_lines.append(f"  - Prompt Tokens: {usage.get('promptTokenCount', 0):,}\n")
                md_lines.append(f"  - Candidates Tokens: {usage.get('candidatesTokenCount', 0):,}\n")
                md_lines.append(f"  - Total Tokens: {usage.get('totalTokenCount', 0):,}\n")
        
        md_lines.append("\n---\n")
    
    # íŒŒì¼ ì €ì¥
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(''.join(md_lines))
    
    print(f"âœ… ë³€í™˜ ì™„ë£Œ: {output_file}")
    print(f"   - ëŒ€í™” ê°œìˆ˜: {len(data['conversationLog'])}")
    print(f"   - ì¶œë ¥ í¬ê¸°: {len(''.join(md_lines)):,} ë¬¸ì")

if __name__ == '__main__':
    json_file = 'LLM_Conversation_20260101_013724.json'
    output_file = 'LLM_Conversation_20260101_013724.md'
    
    convert_json_to_markdown(json_file, output_file)
